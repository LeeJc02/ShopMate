#!/usr/bin/env python3
"""
RAG å¬å›ç‡è¯„æµ‹è„šæœ¬

è¯„æµ‹æŒ‡æ ‡ï¼š
- æ¥æºå¬å›ç‡ (Source Recall): é¢„æœŸæ–‡æ¡£æ˜¯å¦å‡ºç°åœ¨å¬å›ç»“æœä¸­
- å…³é”®è¯å‘½ä¸­ç‡ (Keyword Hit Rate): å¬å›å†…å®¹æ˜¯å¦åŒ…å«é¢„æœŸå…³é”®è¯
- å¹³å‡å¬å›æ•°é‡: æ¯æ¬¡æŸ¥è¯¢å¬å›çš„æ–‡æ¡£å—æ•°
"""

import json
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.rag import KnowledgeRetriever


def load_eval_dataset(dataset_path: Path) -> dict:
    """åŠ è½½è¯„æµ‹æ•°æ®é›†"""
    with open(dataset_path, "r", encoding="utf-8") as f:
        return json.load(f)


def evaluate_rag(retriever: KnowledgeRetriever, dataset: dict, k: int = 3) -> dict:
    """
    æ‰§è¡Œ RAG å¬å›ç‡è¯„æµ‹
    
    Args:
        retriever: çŸ¥è¯†åº“æ£€ç´¢å™¨
        dataset: è¯„æµ‹æ•°æ®é›†
        k: å¬å›æ–‡æ¡£æ•°
        
    Returns:
        è¯„æµ‹ç»“æœ
    """
    results = {
        "total_cases": 0,
        "source_recall_hits": 0,
        "keyword_total": 0,
        "keyword_hits": 0,
        "avg_docs_retrieved": 0,
        "details": [],
    }
    
    total_docs = 0
    
    for case in dataset["test_cases"]:
        query = case["query"]
        expected_sources = case["expected_sources"]
        expected_keywords = case["expected_keywords"]
        
        # æ‰§è¡Œæ£€ç´¢
        docs = retriever.search(query, k=k)
        
        # è·å–å¬å›çš„æ¥æº
        retrieved_sources = [doc.metadata.get("filename", "") for doc in docs]
        retrieved_content = " ".join([doc.page_content for doc in docs])
        
        # è®¡ç®—æ¥æºå¬å›
        source_hit = any(src in retrieved_sources for src in expected_sources)
        
        # è®¡ç®—å…³é”®è¯å‘½ä¸­
        keyword_hits = sum(1 for kw in expected_keywords if kw in retrieved_content)
        
        results["total_cases"] += 1
        if source_hit:
            results["source_recall_hits"] += 1
        
        results["keyword_total"] += len(expected_keywords)
        results["keyword_hits"] += keyword_hits
        
        total_docs += len(docs)
        
        # è¯¦ç»†ç»“æœ
        results["details"].append({
            "id": case["id"],
            "query": query,
            "category": case.get("category", ""),
            "source_recall": source_hit,
            "keyword_hit_rate": keyword_hits / len(expected_keywords) if expected_keywords else 0,
            "retrieved_sources": retrieved_sources,
        })
    
    # è®¡ç®—æ±‡æ€»æŒ‡æ ‡
    results["source_recall_rate"] = results["source_recall_hits"] / results["total_cases"]
    results["keyword_hit_rate"] = results["keyword_hits"] / results["keyword_total"] if results["keyword_total"] > 0 else 0
    results["avg_docs_retrieved"] = total_docs / results["total_cases"]
    
    return results


def print_results(results: dict):
    """æ‰“å°è¯„æµ‹ç»“æœ"""
    print("\n" + "=" * 60)
    print("ğŸ“Š RAG å¬å›ç‡è¯„æµ‹ç»“æœ")
    print("=" * 60)
    
    print(f"\nğŸ“ˆ æ±‡æ€»æŒ‡æ ‡:")
    print(f"   æµ‹è¯•ç”¨ä¾‹æ•°: {results['total_cases']}")
    print(f"   æ¥æºå¬å›ç‡: {results['source_recall_rate']:.1%} ({results['source_recall_hits']}/{results['total_cases']})")
    print(f"   å…³é”®è¯å‘½ä¸­ç‡: {results['keyword_hit_rate']:.1%} ({results['keyword_hits']}/{results['keyword_total']})")
    print(f"   å¹³å‡å¬å›æ–‡æ¡£æ•°: {results['avg_docs_retrieved']:.1f}")
    
    print(f"\nğŸ“‹ è¯¦ç»†ç»“æœ:")
    print("-" * 60)
    
    for detail in results["details"]:
        status = "âœ…" if detail["source_recall"] else "âŒ"
        kw_rate = f"{detail['keyword_hit_rate']:.0%}"
        print(f"   {status} [{detail['id']}] {detail['query'][:30]}...")
        print(f"      åˆ†ç±»: {detail['category']} | å…³é”®è¯å‘½ä¸­: {kw_rate}")
        print(f"      å¬å›æ¥æº: {', '.join(detail['retrieved_sources'])}")
    
    print("\n" + "=" * 60)
    
    # è¯„åˆ†å»ºè®®
    recall_rate = results["source_recall_rate"]
    if recall_rate >= 0.9:
        print("ğŸ‰ ä¼˜ç§€ï¼å¬å›ç‡è¶…è¿‡ 90%")
    elif recall_rate >= 0.7:
        print("ğŸ‘ è‰¯å¥½ï¼å»ºè®®ä¼˜åŒ–æ–‡æ¡£åˆ‡åˆ†ç­–ç•¥")
    else:
        print("âš ï¸ éœ€è¦ä¼˜åŒ–ï¼å»ºè®®æ£€æŸ¥ç´¢å¼•æ„å»ºå’ŒæŸ¥è¯¢ç­–ç•¥")


def save_results(results: dict, output_path: Path):
    """ä¿å­˜è¯„æµ‹ç»“æœ"""
    results["timestamp"] = datetime.now().isoformat()
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {output_path}")


def main():
    print("ğŸ” å¼€å§‹ RAG å¬å›ç‡è¯„æµ‹...")
    
    # åŠ è½½æ•°æ®é›†
    dataset_path = project_root / "data" / "eval" / "rag_eval_dataset.json"
    dataset = load_eval_dataset(dataset_path)
    print(f"ğŸ“š åŠ è½½è¯„æµ‹æ•°æ®é›†: {len(dataset['test_cases'])} ä¸ªæµ‹è¯•ç”¨ä¾‹")
    
    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever = KnowledgeRetriever(
        persist_directory=project_root / "chroma_data",
        collection_name="customer_service_kb",
    )
    
    # æ‰§è¡Œè¯„æµ‹
    results = evaluate_rag(retriever, dataset, k=3)
    
    # æ‰“å°ç»“æœ
    print_results(results)
    
    # ä¿å­˜ç»“æœ
    output_path = project_root / "data" / "eval" / "rag_eval_results.json"
    save_results(results, output_path)


if __name__ == "__main__":
    main()
